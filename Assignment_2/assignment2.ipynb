{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9cX55RiefyZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dT0k9iMN7Qz"
      },
      "source": [
        "# ***Assignment 2***\n",
        "Welcome to Assignment 2! In this assignment you are allowed to work ***individually or in pairs***. It is worth 30 points in total. Exercises 1 is worth 5 points, exercise 2 is worth 10 points, and 3 can give you 15 points.\n",
        "\n",
        "There is a 5 point minimum for passing this assignment (you need to pass all four assignments to be able to pass the course).\n",
        "\n",
        "Submission details: Your submission should contain two pdf's.\n",
        "\n",
        "1. A pdf version of your filled out colaboratory on Canvas. You can do this by pressing `cmd/ctrl+p` (you know the drill from there).  \n",
        "2. For exercise 1, you need to hand in your hand-written solutions in a LaTeX pdf. We only accept solutions written in LaTeX, i.e. not Word or any other text editor. We recommend [Overleaf](https://overleaf.com), if you do not already have a favourite LaTeX editor (which is also [provided by KTH](https://intra.kth.se/en/it/programvara-o-system/programvara/installera/download/overleaf/overleaf-1.932755))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp9dXr2ULwzZ"
      },
      "source": [
        "# Contents\n",
        "In this assignment we will experiment with the following topics (not necessarily in this order):\n",
        "* Conjugate priors\n",
        "* Gibbs sampling\n",
        "* Metropolis-Hastings\n",
        "* Convergence diagnostics\n",
        "* Probabilistic modelling\n",
        "* Bayesian decision theory\n",
        "* The Predictive posterior distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrXaIaQZQTky"
      },
      "source": [
        "# ***1. Conjugate Priors***\n",
        "\n",
        "Conjugate distributions are very important and widely used distributions in Bayesian statistics. Having a closed-form expression for the posterior distribution provides great convenience.\n",
        "\n",
        "It is important to feel confident with derivations and being able to find closed-form expressions. For this task, we give you well-known likelihood functions & prior distributions and ask you to *derive* the closed form expressions of the posterior distributions.\n",
        "\n",
        "For this exercise, you need to hand in your hand-written solutions in a LaTeX pdf. We only accept solutions written in LaTeX.\n",
        "\n",
        "**Q1.1 There are $N$ i.i.d. data points sampled from a Normal distribution; $\\mathcal{N}(x_i | \\mu, \\sigma^2)$ for $i \\in[N]$ where $\\mu$ is the mean and $\\sigma^2$ is the variance. Assume $\\sigma^2$ is known and the mean has the Normal prior distribution $\\mathcal{N}(\\mu | \\mu_0, \\sigma_0^2)$. \n",
        "Show the posterior distribution of mean is \n",
        "\\begin{align*}\n",
        "\\mathcal{N} \\left( \\mu \\;|\\; \\frac{\\sigma^2_0 N}{\\sigma^2+N\\sigma^2_0}\\bar{x} +   \\frac{\\sigma^2}{\\sigma^2+N\\sigma^2_0}\\mu_0, \\; \\left( \\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}\\right) ^{-1} \\right) \\\\\n",
        "\\end{align*} \n",
        "where $\\bar{x}$ is the sample mean.**\n",
        "\n",
        "**Q1.2 There are $N$ i.i.d. data points sampled from a Normal distribution; $\\mathcal{N}(x_i | \\mu, \\sigma^2)$ for $i \\in[N]$ where $\\mu$ is the mean and $\\sigma^2$ is the variance. Assume $\\mu$ is known and the variance has the Inverse-Gamma prior distribution $\\mathcal{IG}(\\sigma^2 | \\alpha, \\beta)$. Show the posterior distribution of variance is\n",
        "\\begin{align*}\n",
        "\\mathcal{IG}\\left( \\sigma^2 \\;|\\; \\alpha + \\frac{N}{2}, \\; \\beta+\\frac{1}{2}\\sum_{i=1}^N (x_i - \\mu)^2 \\right)\n",
        "\\end{align*}\n",
        ".**\n",
        "\n",
        "**Q1.3 There are $N$ i.i.d. data points sampled from a Normal distribution; $\\mathcal{N}(x_i | \\mu, \\tau^{-1})$ for $i \\in[N]$ where $\\mu$ is the mean and $\\tau=1/\\sigma^2$ is the precision. Assume $\\mu$ has the Normal prior $\\mathcal{N}(\\mu | \\mu_0, (n_0 \\tau)^{-1})$ and the precision has the Gamma prior distribution $Ga(\\tau | \\alpha, \\beta)$. \n",
        "Show the posterior distributions of mean and precision are\n",
        "\\begin{align*}\n",
        "&\\mathcal{N}\\left( \\mu \\;|\\; \\frac{N}{N+n_0}\\bar{x} +\\frac{n_0}{N+n_0}\\mu_0, \\; (N\\tau+n_0\\tau)^{-1} \\right)\\\\\n",
        "&Ga\\left(\\tau \\;|\\; \\alpha + \\frac{N}{2}, \\; \\beta+\\frac{1}{2}\\sum_{i=1}^N (x_i - \\bar{x})^2 + \\frac{N n_0}{2(N+n_0)}(\\bar{x}-\\mu_0)^2 \\right)\n",
        "\\end{align*} \n",
        "where $\\bar{x}$ is the sample mean.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryXnXeUnhsC_"
      },
      "source": [
        "# ***2. The Two-Dimensional Gaussian***\n",
        "\n",
        "Consider the following posterior, $$p(\\theta|x) = \\mathcal{N}\\left(\\theta|x, \\Sigma\\right),$$ where $\\theta=(\\mu_1, \\mu_2)$ are the unknown means of the Gaussian distribution that generated $x = (x_1, x_2)$, i.e. $$x \\sim \\mathcal{N}(x| \\theta, \\Sigma).$$ Furthermore, the covariance matrix is known, $$\\Sigma = \\left(\\begin{matrix} 1 & 0.8 \\\\0.8 & 1 \\end{matrix}\\right),$$ and the prior on $\\theta$ is uniform.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dRKQ8z9lBTt"
      },
      "source": [
        "**Q2.1 Use Bayes' rule to derive the considered posterior, given what you know above. That is, clearly specify the joint distribution, the likelihood function, the prior distribution and the marginal likelihood, and then show that $p(\\theta|x) = \\mathcal{N}(\\theta|x, \\Sigma)$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo6AN-Wsp9Q1"
      },
      "source": [
        "*Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgLWtf_Bp5Sb"
      },
      "source": [
        "Although this problem is not intractable, we are now going to use MCMC to sample from the posterior. We will assume that $x = (0, 0)$.\n",
        "\n",
        "Before we start using MCMC, let's utilize that we know the posterior distribution by sampling from it directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8ipbLjusjLc"
      },
      "source": [
        "**Q2.2 Sample 10000 values of $\\theta$ from $p(\\theta|x)$. Visualize the samples in a scatter plot.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkmSJkqfuBBk"
      },
      "source": [
        "Now we shall generate and compare samples from two MCMC algorithms, specifically the Metropolis-Hastings (MH) algorithm and Gibbs sampling. Recall that in MCMC algorithms we are evaluating our Markov chain samples using the joint distribution, and not the posterior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhUEuV_Et66D"
      },
      "source": [
        "**Q2.3 Let the proposal distribution $q(\\theta'|\\theta^{t})$ be a Gaussian with $\\sigma^2$ variance. Write an MH algorithm that samples 10k points from $p(\\theta|x)$, and scatter plot the samples.**\n",
        "\n",
        "**Tune $\\sigma^2$ so that the MH samples are similar to those generated in Q2.1, and report $\\sigma^2$.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Wi7lD2KxVfn"
      },
      "source": [
        "**Q2.4 Derive the conditionals $p(\\theta_1|\\theta_2^{t}, x)$ and $p(\\theta_2|\\theta_1^{t}, x)$.**\n",
        "\n",
        "**Write a Gibbs sampler which you then use in order to generate 10k samples from $p(\\theta|x)$. Scatter plot the results.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAdXpYC8IuTw"
      },
      "source": [
        "# ***3. The Bayesian Burglars***\n",
        "\n",
        "In this assignment we will act as burglars who decide whether to break into a house or not using Bayesian decision theory.\n",
        "\n",
        "Let $C(x, h)$ be the cost of decision $x$ given the state, $h$. $x\\in\\{0, 1\\}$ is the decision to break in or not, and $h\\in\\{0,1\\}$ tells us if the house owners are home or not. The break-in would last during the time interval $Δt$ and we can not know $h$ during $Δt$ before taking a decision. In order to be data driven decision makers, we have collected $N$ data points, $\\mathcal{D}=\\{y_i, \\tau_i\\}_{i=1}^N$, where $y_i$ is a binary variable indicating if the home owners are home, and $\\tau_i$ is the time point of the observation.\n",
        "\n",
        "Based on our data, we seek to take a Bayesian approach to the problem. Namely, we want to compute the *Bayes risk* associated with breaking and entering *or not* breaking and entering during a given time slot $$\\mathcal{R}(Δt) = \\sum_{x=0}^1\\mathbb{E}_{p(h|Δt, \\mathcal{D})}\\left[ C(x, h)\\right],$$ where $$p(h|Δt, \\mathcal{D}) = \\int_0^1 p(h, \\theta|Δt, \\mathcal{D}) d\\theta = \\int_0^1 p(h|\\theta)p(\\theta|Δt, \\mathcal{D}) d\\theta,$$ is the predictive posterior distribution, and $\\theta$ is the probability that the house owners are home.\n",
        "\n",
        "***Take a moment to appreciate how powerful the Bayes risk quantity is. Yes, here we are using it in a silly setting, but it is widely applicable to all sorts of advanced and simple problems where it makes sense to quantify the risk or expected gain.***\n",
        "\n",
        "Let's rewrite the risk expression in terms of the predictive posterior $$\\mathcal{R}(Δt) = \\sum_{x=0}^1\\mathbb{E}_{\\int p(h|\\theta) p(\\theta|Δt, \\mathcal{D})d\\theta}\\left[ C(x, h)\\right]$$ and write out the posterior over $\\theta$ using Bayes' rule $$p(\\theta|Δt, \\mathcal{D}) = \\frac{p(\\mathcal{D}|\\theta, \\Delta t)p(\\theta)p(Δt)}{p(\\mathcal{D}, Δt)}.$$\n",
        "Unfortunately, $p(\\theta|Δt, \\mathcal{D})$ is intractable as it involves the computation of a nasty marginal likelihood. However, we *do* know how to compute the joint distribution (the numerator), so we decide to solve the problem using a Metropolis-Hastings algorithm!\n",
        "\n",
        "To summarize the objective of the exercise, we want to compute the risk function above. To do this, we need to compute an expectation with respect to the intractable posterior predictive distribution. Instead, we can approximate the posterior predictive by sampling from the posterior over $\\theta$ via MH. Then, using the approximation of $p(h|Δt, \\mathcal{D})$, the risk function can be computed for both choices of $x$. The exercise is divided into a series of subproblems.\n",
        "\n",
        "****\n",
        "\n",
        "## **The distributions and functions in the generative model**\n",
        "\n",
        "**The likelihood function** is a conditional Bernoulli likelihood $$p(\\mathcal{D}|\\theta, \\Delta t) = \\prod_{i=1}^N \\theta^{\\mathbb{1}\\{(y_i = 1)\\wedge (\\tau_i \\in \\Delta t)\\}}(1-\\theta)^{\\mathbb{1}\\{(y_i = 0)\\wedge (\\tau_i \\in \\Delta t)\\}}(1/2)^{\\mathbb{1}\\{\\tau_i \\notin \\Delta t\\}},$$ where $\\wedge$ is the logical \"AND\" character.\n",
        "\n",
        "**The $\\theta$ prior** is a Beta distribution $$p(\\theta) = \\text{Beta}(\\theta|\\alpha, \\beta)$$ with hyperparams $\\alpha, \\beta$.\n",
        "\n",
        "**The $\\Delta t$ prior**, i.e. the prior belief of during which time slot it is appropriate to perform the break in, is unnormalized and factorisable $$p(\\Delta t) = p(t_u|t_l)p(t_l)$$ with $$p(t_l) = \\mathbb{1}\\{t_l\\in [0, 3600\\cdot24]\\}$$ and $$p(t_u|t_l) = \\mathbb{1}\\{t_u\\in [t_l + 3600, 3600\\cdot24]\\},$$ where $t_u$ denotes upper bound of the break-in time slot, and $t_l$ the lower bound. In other words, when the break in ends and starts. At shortest, the break in has to last one hour, $3600$ seconds, which is reflected in the trunctation using the lower bound in $p(t_u|t_l)$.\n",
        "\n",
        "****\n",
        "\n",
        "## **The proposal distributions in the MH algorithm**\n",
        "\n",
        "**The proposal for $\\theta$** is a mirrored uniform distribution with step size $\\epsilon$, conditioned on the previous state, $\\theta^{(k-1)}$.\n",
        "\n",
        "**The proposal for $t_l$** is a normal distribution with step size $\\sigma^2$, conditioned on the previous state value for $t_l$, $t_l^{(k-1)}$.\n",
        "\n",
        "**The proposal for $t_u$** is a truncated exponential distribution with CDF $$F(t_u|t_l, \\lambda) = 1 - e^{-\\lambda(t_u - U)},$$ and rate parameter $\\lambda.$ Here $U = 3600 + t_l$ is the size of the truncation, which ensures that proposed ending times for the break in occur at least $3600$ seconds after the proposed start of the break in, $t_l$.\n",
        "\n",
        "**Q3.1 In the following three subproblems, you will define and visualize the proposals**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ns1JYkC2AjX"
      },
      "source": [
        "**Q3.1.1.\n",
        "A mirrored (one-dimensional) uniform distribution only admits density in a specified interval, *mirroring back* whatever part of its support falls outside the interval back on to the interval. The density that falls outside the interval is superpositioned on top of the non-mirrored density.**\n",
        "\n",
        "**Using indicator functions, formulate the pdf $q(\\theta|\\theta^{(k-1)})$. Implement the distribution in numpy (you should be able to sample from it, and evaluate its likelihood). Show are you are able to sample from it by sampling 1000 samples and plotting them in a histogram. Use $\\theta^{(k-1)}=0.2$ and $\\epsilon = 0.3$ when sampling**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAKdr1ay59rD"
      },
      "source": [
        "**Q3.1.2 Formulate the pdf of $q(t_l|t_l^{(k-1)})$ with a variable $\\sigma^2$. You will need to choose a step size, $\\sigma^2$, before starting the experiment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baCZwR3677KA"
      },
      "source": [
        "**Q3.1.3 Use the given CDF to formulate the pdf of the proposal distribution, $q(t_u|t_l)$. Sampling from this pdf is not directly supported in numpy. Use the inverse-sampling trick to sample 1000 samples from it as you let $t_l=0$. Visualize the histrogram of the samples with a plot.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epa8CVFn9gZe"
      },
      "source": [
        "****\n",
        "# **Generating data and implementing the algorithm**\n",
        "Next we need data. Use the following cell to generate the data and take a moment to reflect about the data-generating process. Beyond this cell, we will forget about the underlying data-generating process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-8FM6YjC-o7j",
        "outputId": "88c04188-2a7b-4001-ddde-08b9a7b30972"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "def generate_data(N=30):\n",
        "    # we more frequently go to collect data during the middle of the day\n",
        "    part_of_day = np.argmax(\n",
        "        np.random.multinomial(1, [1/4, 1/2, 1/4], N), axis=-1\n",
        "        )\n",
        "    time_intervals_low = np.array([0.0, 8 * 3600, 17 * 3600])\n",
        "    time_intervals_high = np.array([8 * 3600, 17 * 3600, 24 * 3600])\n",
        "\n",
        "    # after deciding which part of the day to go collect data,\n",
        "    # the exact time point is uniformly chosen\n",
        "    tau_i = np.random.uniform(low=time_intervals_low[part_of_day],\n",
        "                      high=time_intervals_high[part_of_day])\n",
        "\n",
        "    # probabilities that the owners are home or not depend on the part of the day\n",
        "    home_prob = np.array([0.9, 0.2, 0.7])\n",
        "\n",
        "    # randomly sample the event that the owners are home\n",
        "    u = np.random.uniform(0, 1, N)\n",
        "    y_i = (u < home_prob[part_of_day]).astype(float)\n",
        "\n",
        "    # the data is composed of N combinations of home-or-not events and time points\n",
        "    return y_i, tau_i\n",
        "\n",
        "\n",
        "# do not change the seed or the number of observations, N\n",
        "np.random.seed(0)\n",
        "D = generate_data(N=20)\n",
        "\n",
        "idx = np.argsort(D[1])\n",
        "plt.plot(D[1][idx] / 3600., D[0][idx], '*', label='home or not')\n",
        "plt.axvline(8, 0, 1, c='r', label='08.00')\n",
        "plt.axvline(17, 0, 1, c='g', label='17.00')\n",
        "plt.xlabel('Time (hours)')\n",
        "plt.ylabel('Home (yes/no)')\n",
        "plt.yticks([0, 1])\n",
        "plt.xticks(np.arange(25))\n",
        "plt.legend(loc='center left')\n",
        "plt.title('Distribution of the observations')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8r88ThJRYbN"
      },
      "source": [
        "**Q3.2 Implement the MH algorithm. Run it until convergence, where you decide when the chains have convergenced. Motivate your convergence statement by using the convergence diagnostics discussed in the lectures. Convey your arguments with plots and numbers. A mandatory convergence diagnostic is to run and compare multiple chains.**\n",
        "\n",
        "**Before you are ready to implement the algorithm, you need to select the two step sizes, $\\epsilon$ and $σ^2$. Specify clearly your choices, and motivate them. There are no right or wrong choices, but better or worse alternatives. It is OK to revise your choices after evaluating the acceptance ratio of the MH algorithm, but here you should share your a priori beliefs.**\n",
        "\n",
        "**Finally, let $\\lambda=900$ and $\\alpha=\\beta=1$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0H1Ku6bTeOP"
      },
      "source": [
        "*Answer question regarding choice of $\\epsilon$ here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRyZ-15nTlAl"
      },
      "source": [
        "*Answer question regarding choice of $\\sigma^2$ here*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N31Aws8oTn9O"
      },
      "outputs": [],
      "source": [
        "# implement the MH algorithm here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25irRGoYUljq"
      },
      "source": [
        "****\n",
        "# **Analysis**\n",
        "\n",
        "After performing our convergence diagnostics and tuning our MH algorithm based on the convergence analysis, we are now content with our MH samples. It is time to evaluate the Bayes risk.\n",
        "\n",
        "Let $$C(x=1, h) = \\begin{cases}500 &: h = 0\\\\ -10000 &: h=1 \\end{cases}$$ and $$C(x=0, h) = -1000, \\text{for $h=0$ and $h=1$.}$$\n",
        "\n",
        "**Q3.3.1 Explain this cost function in words.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVuhdwVOZCs-"
      },
      "source": [
        "*Answer here*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb6bgNH1Z_YC"
      },
      "source": [
        "**Q3.3.2 Compute the risk of breaking in or not breaking in between 01.00-02.00, 13.00-14.00, and between 21.00-22.00. According to the results, when should we break in? Explain the results.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdtQNIGUeOWy"
      },
      "source": [
        "****\n",
        "# **Modifying the model**\n",
        "A problem with the above model is that it does not let us incorporate our prior believes of ***when*** it is more probable that the home owners are home. It is reasonable to believe that the house is empty more often during day time than night time, for instance.\n",
        "\n",
        "**Q3.4 (Worth 5 points)**\n",
        "\n",
        "\n",
        "Here, modify the prior on $\\theta$ such that its hyperparameters depend on $Δt$, resulting in higher a priori probability that the house is empty between 08.00 and 17.00. Hint: use indicator functions. Clearly formulate the new generative model.\n",
        "\n",
        "After the modification of the model, rerun the experiments above and re-evaluate the risks. ***Do not delete your previous results in the cells above! Neatly organize new code and text cells below.***\n",
        "\n",
        "What are your reflections on the results after the modification?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
